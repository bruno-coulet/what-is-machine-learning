# what-is-machine-learning

## Contexte du projet
Travail personnel de recherches et de documentation pour la d√©finition des √©l√©ments suivants :


1. [Science des donn√©es](#science-des-donn√©es)
2. [Apprentissage automatique ](#apprentissage-automatique)
3. [Apprentissage supervis√©](#apprentissage-supervis√©)
4. [Apprentissage non supervis√©](#apprentissage-non-supervis√©)
5. [Classification supervis√©e](#classification-supervis√©e)
6. [Classification non supervis√©e](#classification-non-supervis√©e)
7. [R√©gression](#r√©gression)
8. [Validation crois√©e](#validation-crois√©e)
9. [Donn√©es d'entra√Ænement, de test, de validation](#donn√©es-dentra√Ænement-de-test-de-validation)
10. [Corr√©lation lin√©aire (de pearson) entre deux variables](#corr√©lation-lin√©aire-de-pearson-entre-deux-variables)
11. [Fonction de co√ªt](#fonction-de-co√ªt)
12. [Descente de gradient](#descente-de-gradient)


## Sources
<div class="encadre">

   - Machine learning avec Scikit-Learn
   de Aur√©lien G√©ron aux editions Dunod O'reilly
   2017
   - Machine learning : les fondamentaux : exploiter des donn√©es structur√©es en Python
   de Harrison Matt aux √©ditions O'Reilly Media
   2020
   - [StatQuest](https://statquest.org/video-index/) et sa [cha√Æne youtube](https://www.youtube.com/watch?v=fSytzGwwBVw&list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF&index=3)
   - [Datatab.fr](https://datatab.fr/tutorial/regression)
   - math.univ-angers.fr/labatte/enseignement/master/classificationsupervisee.pdf
   - [IBM](https://www.ibm.com/fr-fr/topics/machine-learning)
   - [CNIL](https://www.cnil.fr/fr/definition/apprentissage-automatique)
   - [ekinox.io](https://blog.ekinox.io/ml/normalisation-series-temporelles)
   - [wikipedia](https://fr.wikipedia.org/wiki/Apprentissage_automatique)

</div>

## Science des donn√©es
Ou comment g√©n√©rer du sens √† partir de donn√©es - *Faire parler les donn√©es*.
<p align="center">
<img src="img/dataScience.png" alt="data_science">
</p>
Consid√©r√©e comme un nom alternatif pour les statistiques dans les ann√©es 60, la science des donn√©es devient une discipline issue de l'informatique √† la fin des ann√©es 90.
<br>
Elle s'articule autour de la donn√©e :

- conception.
- collecte.
- analyse.

L'objet de cette science est l'√©tude et l'analyse des donn√©es afin d'en extraire des informations pertinentes pour les entreprises.

Elle adopte une approche pluridisciplinaire, m√™lant des concepts et des m√©thodes issus des **math√©matiques**, des **statistiques**, de l'**intelligence artificielle** et de l'**informatique**.

L'objectif est d'examiner de vastes ensembles de donn√©es pour r√©pondre √† des questions cl√©s telles que :
- Que s'est-il pass√© ?
- Pourquoi cela s'est-il produit ?
- Que va-t-il se passer ?
- Quelles actions peut-on entreprendre sur la base de ces r√©sultats ?

4 formes d'analyse principale se d√©gagent :
1. **Analyse descriptive**
visualisation de donn√©es
2. **Analyse diagnostique**
exploration, transformation, corr√©lation...
3. **Analyse pr√©dictive**
machine learning, la pr√©diction, la comparaison de mod√®les et la mod√©lisation pr√©dictive.
4. **Analyse prescriptive**
suite logique et proactive de l'analyse pr√©dictive
<br>
[Retour √† l'index](#contexte-du-projet)
<br>
## Apprentissage automatique
L'art de programmer des ordinateurs de sorte qu'ils puissent apprendre √† partir de donn√©es

On consid√®re qu'un ordinateur "apprend" s'il am√©liore sa **[performance](#fonction-de-co√ªt)** lors de l'ex√©cution d'une **t√¢che** au fur et √† mesure de son **exp√©rience**.

Il existe 2 grandes familles d'apprentissage automatique :
#### La classification - pr√©dire des classes
Pr√©dire une cat√©gorie ou une √©tiquette √† partir des caract√©ristiques des donn√©es d'entr√©e.
**exemple :**  filtre de spam √† partir d'e-mail accompagn√©s de leur classe (normal/spam) 

#### La r√©gression - pr√©dire des valeurs
Pr√©dit une valeur num√©rique **cible (target)** √† partir des valeurs **caract√©ristiques (feature)** d'attributs ou de variables d'une observation

**exemple :** pr√©dire le prix d'une voiture en fonction de son age, de son kilom√©trage, etc...

### Terminologie :


**variable explicative :** caract√©ristique
**caract√©ristique :** un attribut et sa valeur (ex: kilom√©trage = 58 000 km)
**variable √† expliquer :** √©tiquette
**attribut :** type de donn√©e (ex: kilom√©trage)
 **intercept** : dans une √©quation de r√©gression lin√©aire, c'est le terme constant ($ \theta_0 $), repr√©sentant la valeur de la variable √† expliquer lorsque toutes les variables explicatives sont √©gales √† z√©ro. C'est le point d'intersection avec l'axe des ordonn√©es.
**biais** : synonyme d'intercept dans les mod√®les de r√©gression. Il repr√©sente l'ajustement constant n√©cessaire pour mieux pr√©dire la variable √† expliquer, ind√©pendamment des variables explicatives. Dans un mod√®le d'apprentissage automatique, c'est la valeur qui est ajout√©e avant d'appliquer les coefficients aux variables explicatives.

Intercept et biais sont souvent utilis√©s de mani√®re interchangeable, en particulier dans le contexte de mod√®les de r√©gression, o√π le biais ajuste la sortie avant d'appliquer les coefficients aux variables explicatives.


[Retour √† l'index](#contexte-du-projet)


##  Apprentissage profond
<p align="center">
   <img src ="img/deep_learning.png" alt ="deep learning">
</p>
Proc√©d√© d‚Äôapprentissage automatique utilisant des [r√©seaux de neurones](reseaux_neurones.md)


 compos√© de nombreuses couches cach√©es et des algorithmes avec de tr√®s nombreux param√®tres.
Ce proc√©d√© requi√®re une grande quantit√© de donn√©es afin d‚Äô√™tre entra√Æn√©.

<p align="center">
  <img src="img/reseauNeurones.png" alt="reseau de neurones">
</p>

A permis des progr√®s importants et rapides :
- analyse du signal sonore, reconnaissance faciale
- analyse du signal visuel, reconnaissance vocale
- le traitement automatis√© du langage

Le d√©veloppement de l'apprentissage profond √† √©t√© rendu possible par des investissements priv√©s et publics importants, notamment de la part des GAFAM, durant les ann√©es 2000.
<br>
[Retour √† l'index](#contexte-du-projet)
<br>

## Apprentissage supervis√©
Les donn√©es d'entrainement fournies √† l'algorithme comportent des **√©tiquettes** qui indiquent le r√©sultat voulu.
Les donn√©es sont caract√©ris√© par des variable x (**features**), et annot√© d'une variable y (**label/target**)
<p align="center">
  <img src="img/etiquette.png" alt="√©tiquette">
</p>

L'objectif de l'algorithme est d'apprendre √† faire correspondre les entr√©es aux sorties afin de pouvoir pr√©dire l'√©tiquette correcte pour de nouvelles donn√©es jamais vues.
<p align="center">
  <img src="img/apprentissage_supervise.png" alt="apprantissage supervis√©">
</p>


[Retour √† l'index](#contexte-du-projet)


## Apprentissage non supervis√©
Les donn√©es d'entrainement ne comportent **pas d'√©tiquettes**.
L'algorithme n'a donc pas d'informations sur le r√©sultat attendu.
Il explore les donn√©es pour y d√©couvrir des structures, des motifs ou des relations cach√©es sans qu'une sortie sp√©cifique ne lui soit fournie.
Il tente d'organiser les donn√©es selon leurs similarit√©s ou diff√©rences.

|                 | Apprentissage supervis√©            | Apprentissage non supervis√©           |
|-----------------------|------------------------------------|--------------------------------------|
| Donn√©es               | √âtiquet√©es                         | Non √©tiquet√©es                      |
| Objectif              | Pr√©dire une sortie                 | D√©couvrir des structures            |
| Types de probl√®mes    | Classification, r√©gression         | Clustering, r√©duction de dimensionnalit√© |
| Exemples typiques     | D√©tection de spam, pr√©vision des ventes | Segmentation de clients, d√©tection d'anomalies |



[Retour √† l'index](#contexte-du-projet)
<br>
## Classification / R√©gression
En apprentissage automatique, on distingue les probl√®mes de r√©gression des probl√®mes de classification.

**En r√®gle g√©n√©ral :**
 
 |Classification|Regression|
 |--------------|----------|
 | pr√©diction d'une variable  **qualitative/discr√®te**| pr√©diction d'une variable **quantitative/continue**|



## Classification supervis√©e

La classification supervis√©e est une t√¢che d‚Äôapprentissage supervis√© o√π le mod√®le apprend √† attribuer des cat√©gories ou des labels √† de nouvelles donn√©es en se basant sur des exemples d‚Äôentra√Ænement √©tiquet√©s. Par exemple, classer des emails comme spam ou non-spam.

1. **On dispose d'articles d√©j√† class√©s en rubrique :**
√©conomie, politique, sport, culture...
<p align="center">
  <img src="img/classification_supervise.png" alt="classification supervis√©e">
</p>

2. **On veut classer un nouvel article, lui attribuer une √©tiquette** 


D√©finition des r√®gles permettant de classer des objets dans des classes.

Ces r√®gles se basent sur des variables qualitatives ou quantitatives des
objets √† classer.

Les m√©thodes s'√©tendent souvent √† des variables Y quantitatives (r√©gression).

Un √©chantillon dont le classement est connu est utilis√© pour l'apprentissage des r√®gles de classement.

Il faut ensuite √©tudier la fiabilit√© de ces r√®gles pour les comparer et les appliquer.
Evaluer les cas de sous apprentissage ou de sur apprentissage (complexit√© du mod√®le). 

On utilise souvent un deuxi√®me √©chantillon ind√©pendant, dit de validation ou de test.
<br>
[Retour √† l'index](#contexte-du-projet)
<br>
## Classification non supervis√©e

La classification non supervis√©e est une technique d'apprentissage automatique utilis√©e lorsque les donn√©es ne sont pas accompagn√©es de labels ou d'√©tiquettes pr√©existantes.
L'objectif est d'**identifier des structures** cach√©es **ou des regroupements naturels** dans les donn√©es.

1. On dispose d'**√©l√©ments non class√©s**
   les mots d'un texte ou les clients d'un site e-commerce sans information pr√©alable sur leurs cat√©gories.
<br>
2. On cherche √† les **regrouper en classes en se basant sur leurs similitudes**
  par exemple :
    - les mots ayant des contextes d'utilisation proches
    - les clients ayant des comportements d'achat similaires.
<br>
3. Si l'algorithme attribue la m√™me √©tiquette √† plusieurs √©l√©ments.
   Ils sont suppos√©s √™tre en rapport avec une m√™me th√©matique ou un m√™me comportement, formant ainsi des clusters (groupes).

| 1 | 2 | 3 |
|--------|---------------|----------------|
|![Classification non supervis√©e](img/classification_non_supervise1.png)|![Classification non supervis√©e 2](img/classification_non_supervise2.png)|![Classification non supervis√©e3](img/classification_non_supervise3.png)|

**Exemples courants :**
- Regrouper des articles de presse selon leurs sujets (politique, sport, technologie...).
- Segmenter une client√®le selon ses habitudes d'achat pour du marketing cibl√©.
<br>
[Retour √† l'index](#contexte-du-projet)
<br>
## R√©gression

En math√©matiques, la r√©gression recouvre plusieurs m√©thodes d‚Äôanalyse statistique permettant d‚Äôapprocher une variable √† partir d‚Äôautres qui lui sont corr√©l√©es.

#### R√©gression lin√©aire  {#regression-lineaire}
m√©thode de mod√©lisation de la **relation entre une ou plusieurs variables ind√©pendantes X (en entr√©e) et une variable d√©pendante y (en sortie)** par une droite.

Un mod√®le lin√©aire effectue une pr√©diction en calculant une somme pond√©r√©e de variables d'entr√©e en y ajoutant un terme constant (intercept)

**Autrement dit :** y est une combinaison lin√©aire des features ùëã et un terme d'erreur qui introduit des impr√©cisions ou de la variabilit√©.

[notebook regression_lineaire](regression.ipynb)

**pr√©diction =  somme pond√©r√©e des variables d'entr√©e plus une constante**
c'est √† dire :
|forme scalaire|forme de somme pond√©r√©e|
|:--:|:--:|
|$\hat{y} = \theta_1 x_1 + \theta_2 x_2 + \dots + \theta_n x_n + \theta_0$|$\hat{y} = \sum_{i=0}^{n} \theta_i x_i$|

¬≤<br>

|symbole|signification|
|:--:|:--:|
|$\hat{y}$ | valeur pr√©dite|
|$n$ | nombre de variables|
|$\theta_i$ | param√®tre du mod√®le, coefficient|
|$x_i$ | variable explicative|
|$\theta_0$|	Biais (intercept, constante), valeur de $ùë¶$ lorsque toutes les variables $ùë•_ùëñ$ sont √©gales √† z√©ro|

Peut aussi s'√©crire sous forme [vectorielle ou matricielle](regression_lineaire.md)



#### R√©gression polynomiale
permet de s'ajuster √† des jeux de donn√©es non lin√©aires en introduisant des puissances des variables ind√©pendantes. Elle utilise plus de param√®tres, ce qui la rend plus flexible, mais √©galement plus sujette au surajustement (overfitting).
#### R√©gression logistique
utilis√©e pour des probl√®mes de classification binaire, elle permet de pr√©dire la probabilit√© d'appartenance √† une classe en utilisant une fonction logistique (sigmo√Øde).
#### R√©gression softmax
une g√©n√©ralisation de la r√©gression logistique utilis√©e pour les probl√®mes de classification multiclasse, qui permet de pr√©dire les probabilit√©s d'appartenance √† plusieurs classes.
<br>
[Retour √† l'index](#contexte-du-projet)
<br>

## Validation crois√©e
Dans un projet de Machine Learnig, il faut s√©parer les donn√©es :

- un jeux de donn√©es pour **entrainer** le mod√®le 
- un jeux de donn√©es pour **tester** le mod√®le entrain√©
- un dernier jeux pour **valider** le mod√®le sur de nouvelles donn√©es

**<font color="orange">La validation crois√©e</font>**
Consiste en l'utilisation alternative et conjointe des jeux d'entrainement et de test.
Cela implique d'entrainer/tester le mod√®le plusieurs fois :

1. division du jeux de donn√© en K sous-ensembles
<br>
2. entrainement puis √©valuation du mod√®le K fois
    - en changeant de combinaison jeux d'entrainement / jeux d'√©valuation √† chaque it√©ration
<br>
3. compare les r√©sultats obtenus
<br>

Ainsi, toutes les tranches de donn√©e sont alternativement r√©serv√®es aux test.
Au final, toutes les donn√©es ont servies √† l'entrainement et au test.
Cela permet d'obtenir une estimation plus stable des performances.
N√©cessite l'utilisation d'une [fonction de fitness](#fonction-de-co√ªt)


#### Validation crois√©e avec un dataset divis√© en 4 sous ensemble :

|it√©ration | entrainement | test| r√©sultats|
|:------:|:-------------:|:--------------:|:---------------:|
|**1**|![train_4](img/cross_validation_train_4.png) |  ![test_4](img/cross_validation_test_4.png)|![track_4](img/cross_validation_track_4.png)|
|**2** | entrainement avec les autres tranches|test avec la tranche 2|![track_3](img/cross_validation_track_3.png)|
|**3** | entrainement avec les autres tranches|test avec la tranche 3|![track_2](img/cross_validation_track_2.png)|
|**4** | entrainement avec les autres tranches|test avec la tranche 4|![track_1](img/cross_validation_track_1.png)|



L'id√©al √©tant de faire une **validation crois√©e avec diff√©rent mod√®les** afin de les comparer :
- Logistic regression
- support vector machines
- k-nearest neighbors
- etc...
<p align="center">
  <img src="img/cross_validation_comparaison.png" alt="comparaison des r√©sultats de la cross validation">
</p>


[Retour √† l'index](#contexte-du-projet)

## Donn√©es d'entra√Ænement, de test, de validation
Dans un projet de Machine Learnig, il faut s√©parer les donn√©es :

1. un jeux de donn√©es d'**entrainement** pour ajuster le mod√®le aux donn√©es. **apprendre √† partir des donn√©es.**
2. un jeux de donn√©es de **test** pour √©valuer les performances du mod√®le entrain√©. **√©valuer la qualit√© de l'apprentissage.**
3. un dernier jeux de **validation** pour optimiser le mod√®le et pr√©venir le surajustement.  **affiner et optimiser le mod√®le.**
   (avec de nouvelles donn√©es)
 
Ces trois √©tapes ‚Äì entra√Ænement, test et validation ‚Äì sont essentielles pour garantir que le mod√®le est fiable et performant avant son d√©ploiement.

Apr√®s les phase de collecte, de nettoyage et de pr√©paration des donn√©es :
- recherche de correlations entre les variables
- gestion des variables quantitative (stratification, normalisation, ...)
- gestion des variables qualitative (encodage, onehot encoding, ...)
- combinaison de variables (cr√©ation de nouvelles caract√©ristiques, feature engineering).

Vient la phase de l'**entrainement du mod√®le**.
supervis√© ou non supervis√© selon que les donn√©es contiennent ou non des √©tiquettes (labels)
Il permet d'ajuster le mod√®le choisi aux donn√©es dans le but de faire des pr√©dictions ou de la classification sur de nouvelles donn√©es

## Entrainement

Entrainer un mod√®le consiste √† d√©finir ses param√®tres de telle sorte qu'ils s'ajustent au mieux au jeu d'entrainement

Mesure courante pour indiquer si un mod√®le de **Regression** s'ajuste bien ou pas aux donn√©e d'entrainement :
- **RMSE** racine carr√©e des erreurs quadratique moyenne -(root mean square error)
- **MSE** erreur quadratique moyenne - (mean square error)

Pour entrainer un mod√®le de r√©gression lin√©aire, il faut donc trouver le vecteur $\theta$ qui minimise la RMSE

En pratique, il est plus simple de minimiser la MSE que la RMSE

### Entrainement - M√©thode analytique
Calcul les valeurs des param√®tres du mod√®le qui donnent le meilleur r√©sultat sur le jeu d'entrainement
(qui minimise la fonction de co√ªt)

### Entrainement - Descente de gradient
ou *Gradient Descent* en anglais
Optimisation it√©rative qui modifie graduellement les param√®tres du mod√®le pour minimiser la fonction de co√ªt sur le jeu d'entrainement
**Converge au final vers le m√™me jeu de param√®tres que la m√©thode analytique**

**Probl√©matique :**

**- Surajustement** (overfitting) : le mod√®le apprend trop bien les d√©tails et le bruit des donn√©es d'entra√Ænement, ce qui nuit √† sa capacit√© √† g√©n√©raliser.
**- Sous-ajustement** (underfitting) : le mod√®le est trop simple et ne capte pas la structure sous-jacente des donn√©es.

## test
La phase de test consiste √† √©valuer les performances du mod√®le sur un ensemble de donn√©es qui n'a pas √©t√© utilis√© pendant l'entra√Ænement.
Cela permet d'obtenir une estimation objective de la capacit√© du mod√®le √† g√©n√©raliser ses pr√©dictions sur des donn√©es inconnues.

**√âvaluation des performances :**
On compare les pr√©dictions du mod√®le avec les valeurs du jeu de test.

**M√©triques courantes pour √©valuer les performances :**
- Pr√©cision (Accuracy) : proportion de pr√©dictions correctes.
- Rappel (Recall) : capacit√© du mod√®le √† identifier les √©l√©ments positifs.
- F1-score : moyenne harmonique entre la pr√©cision et le rappel.
- Erreur quadratique moyenne (MSE) : utilis√©e pour les mod√®les de r√©gression.

**Importance du test :**
- Identifier les biais et faiblesses du mod√®le 
- V√©rifier sa capacit√© √† g√©n√©raliser.

## validation
Apr√®s l'entra√Ænement et le test, la validation est une √©tape cruciale.
Elle vise √† affiner le mod√®le et √† s'assurer qu'il fonctionne correctement dans des conditions r√©elles.

- Optimisation des hyperparam√®tres du mod√®le pour am√©liorer ses performances.
- d√©tecter d'√©ventuels probl√®mes
- D√©tecter le surajustement : un mod√®le trop complexe m√©morise les donn√©es au lieu d'apprendre leurs tendances.
- D√©tecter le sous-ajustement : un mod√®le trop simple passe √† c√¥t√© des structures importantes.
- Optimiser les performances : tester diff√©rentes configurations pour maximiser les r√©sultats.
- G√©n√©ralisation : le jeu de validation permet d'estimer comment le mod√®le se comportera sur des donn√©es r√©elles et non vues auparavant.
<br>
[Retour √† l'index](#contexte-du-projet)
<br>
## Corr√©lation lin√©aire (de Pearson) entre deux variables

La corr√©lation lin√©aire de Pearson mesure l'intensit√© et le sens de la relation lin√©aire entre deux variables quantitatives.

Elle est d√©finie par un coefficient, not√© **r**, avec une **valeur comprise entre -1 et 1 :**
| coefficient r|correlation|signification|
|:--:|:-------:|-----|
|**1**| positive forte| si une des variables augmente, l'autre augmente pareillement|
|**0.3**| positive faible| si une des variables augmente, l'autre augmente moins|
|**0**|Aucune corr√©lation lin√©aire| les variables ne pr√©sentent pas de relation lin√©aire claire|
|**- 1**| n√©gative forte| si une des variables augmente, l'autre diminue pareillement|
|**- 0.3**| n√©gative faible| si une des variables augmente, l'autre diminue moins|


La formule du coefficient de Pearson est donn√©e par :
‚Äã$$ r = \frac{\sum (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum (x_i - \bar{x})^2 \sum (y_i - \bar{y})^2}} $$


- **r** : le coefficient de corr√©lation lin√©aire de Pearson  
- **$ x_i $** et **$ y_i $** : les valeurs des deux variables √©tudi√©es  
- **$ \bar{x} $** et **$ \bar{y} $** : les moyennes des variables $ x $et $ y $ 
- Le num√©rateur mesure la covariance entre $ x $et $ y $ 
- Le d√©nominateur normalise cette covariance par le produit des √©carts-types des deux variables  

<br>

**Ci dessous**, pour des jeux de donn√©es √† deux variables :
le coefficient de corr√©lation et le nuage de points correspondant
<p align="center">
  <img src="img/correlation.svg" alt="corr√©lation">
</p>

- **2√®me ligne :** coefficients = 1 ou -1  ind√©pendemment de la pente
- **3√®me ligne :** coefficients nuls alors que les variables ne semblent pas ind√©pendantes !
   relations **non lin√©aires**

<br>

**Matrice de correlation d'un dataset de 4 variables sur les p√©tales de fleurs iris**
<p align="center">
  <img src="img/matrice_correlation.png" alt="matrice de corr√©lation">
</p>

**<font color="orange">Attention :</font>**
- une corr√©lation forte ne signifie pas n√©cessairement une relation causale
- ne d√©tecte pas les relation non lin√©aires (par ex: si x proche de 0, y augmente)

<br>

[Retour √† l'index](#contexte-du-projet)
<br>

## Fonction de co√ªt

Mesure de performance qui permet de savoir si le mod√®le est bien parametr√© :
| fonction|Valeur si le mod√®le est bon|
|--------------|-------------|
|de **fitness** (d'adaptation) | √©lev√©e|
| de **co√ªt** | faible|

La **<font color="orange">fonction de co√ªt</font>** quantifie l'**√©cart entre les pr√©dictions du mod√®le et les valeurs r√©elles**.
L'objectif lors de l'entra√Ænement est de minimiser cette fonction pour am√©liorer la pr√©cision du mod√®le.

Diff√©rents types de fonctions de co√ªt existent selon le probl√®me trait√© :

- [**Erreur quadratique moyenne (MSE)**](#regression-lineaire.md) pour les probl√®mes de **r√©gression**
- **Entropie crois√©e** pour les probl√®mes de **classification**
- **Hinge loss** pour les **SVM (machines √† vecteurs de support)**

Un mod√®le bien param√©tr√© aura donc une fonction de co√ªt faible et, inversement, une fonction de fitness √©lev√©e, indiquant une bonne capacit√© du mod√®le √† g√©n√©raliser sur des donn√©es non vues.

#### A noter
<font color ="orange">La fonction de co√ªt MSE du mod√®le de regression lin√©aire</font> est une **fonction convexe (en cloche)**
Elle √† donc <font color ="orange">un minimum global</font> , mais <font color ="orange">pas de minimum local</font>
C'est aussi une fonction continue, sa pente ne varie jamais abruptement.
<br>
[Retour √† l'index](#contexte-du-projet)
<br>
## Descente de gradient
Ou **Gradient Descent** en anglais **GD**

M√©thode d'entrainement d'un mod√®le de regression lin√©aire par **optimisation it√©rative**
Consiste en une modification graduelle du param√™tre du mod√®le pour diminuer la fonction de co√ªt sur le jeu d'entrainement

Il existe plusieurs variantes :
- Descente de gradient group√©e (batch)
- Descente de gradient par mini-lots
- Descente de gradient stochastique

<br>

La descente de gradient calcule le gradient de la fonction co√ªt au point $\theta$, puis progresse en direction du gradient descendant.

L'id√©e g√©n√©rale est de <font color="orange">corriger petit √† petit les param√®tres pour minimiser la fonction de co√ªt</font>
<font color="orange">
1. calcul le gradient de la fonction co√ªt au point $\theta$ al√©atoire
2. progresse en direction du gradient descendant
3. en fonction du pas : hyperparam√®tre `learning_rate`
</font>


<br>

**Par exemple : Une fonction de type `y  = aX + b`**

<br>
prediction y  = la pente . X + intercept
<br>
Si on connait la pente, pente = 0,64<br><br>
Prenons al√©atoirement `b` ou `intercept` = `0`<br>
Cela permet de tracer une ligne qui passe par `0`<br>
Puis de caluler le carr√© des √©carts entre les valeurs cible du jeux d'entrainement et les valeur de la ligne
  <img src="img/gradient_descent/regression_1.png"/>
On r√©p√®te l'op√©ration avec `intercept`=`0,25`
  <img src="img/gradient_descent/regression_2.png"/>
`intercept`=`0,5`
  <img src="img/gradient_descent/regression_3.png"/>
`intercept`=`0,9`
  <img src="img/gradient_descent/regression_4.png"/>
`intercept`=`1`
  <img src="img/gradient_descent/regression_5.png"/>
`intercept`=`1,3`
  <img src="img/gradient_descent/regression_6.png"/>
  <img src="img/gradient_descent/regression_7.png"/>
  <img src="img/gradient_descent/regression_8.png"/>





<br>

**Diff√©rent pas (taux d'apprentissage) d'une descente de gradient de fonction convexe, , comme la focntion MSE**

![learning rate](img/learning_rate.jpg)

La fonction de co√ªt MSE est convexe, elle √† donc un minimum global, pas de minimum local, pas de variation abrupte de pente.

<font color ="orange">Pour une descente de gradient, toutes les variables doivent avoir la m√™me echelle, sinon la convergence sera plus lente</font>

![Avec et sans normalisation des variable](img/gd_normalize.png)




## Fonction de co√ªt MSE pour le mod√®le de r√©gression lin√©aire

Voir la [fonction de co√ªt](#regression-lineaire.md) du mod√®le de regression lin√©aire

Peut s'√©crire de plusieurs mani√®res :<br>
$MSE(X, h_\theta)$, pour montrer que le mod√®le est param√©tr√© par le vecteur $\theta$<br>$MSE(X, h)$<br>
$MSE(\theta)$ pour simplifier
$$
MSE(X, h_\theta) = \frac{1}{m} \sum_{i=1}^{m} \left( \theta^T x^{(i)} - y^{(i)} \right)^2
$$

S'√©crit aussi

$$J(\theta) = \frac{1}{m} \sum_{i=1}^{m} \left( h_\theta(x^{(i)}) - y^{(i)} \right)^2$$


|symbole|signification|
|:--:|:--------|
|$m$ | nombre total d'exemples dans l'ensemble d'entra√Ænement.|
|$ùë•(ùëñ)$  | vecteur des caract√©ristiques de l'exemple ùëñ|
|$ùúÉ$ | vecteur des param√®tres du mod√®le.|
|$ùúÉùëáùë•(ùëñ)$ <font color = "orange">ou</font> $h (x^{(i)})$ | pr√©diction du mod√®le pour $ùë•(ùëñ)$|
|$y(i)$|valeur r√©elle associ√©e √† $ùë•_i$|
|$ (\theta^T x^{(i)} - y^{(i)})^2 $|erreur quadratique pour un exemple donn√©|
<br>
<br>

## D√©riv√©e partielle par rapport √† un param√®tre $\theta_j$

$$\frac{\partial J(\theta)}{\partial \theta_j} = \frac{1}{m} \sum_{i=1}^{m} \left( h_\theta(x^{(i)}) - y^{(i)} \right) x_j^{(i)}$$

<br>



## D√©riv√©e partielle
On note $‚ÑéùúÉ(x^{(  i)})=ùúÉ^ùëáùë•^{(ùëñ)}$<br><br>
Donc la d√©riv√©e partielle du MSE par rapport √† $\theta_j$  est :


$$
\frac{\partial MSE}{\partial \theta_j} = \frac{1}{m} \sum_{i=1}^{m}2 \left( \theta^T x^{(i)} - y^{(i)} \right) x_j^{(i)}
$$

D√©riv√©e partielle par rapport √† $\theta_j$ simplifi√©e

$$
\frac{\partial MSE}{\partial \theta_j} = \frac{2}{m} \sum_{i=1}^{m} \left( \theta^T x^{(i)} - y^{(i)} \right) x_j^{(i)}
$$




| Symbole               | Signification |
|-----------------------|--------------|
| $MSE(X, h_\theta) $  | Erreur quadratique moyenne (Mean Squared Error) |
| $\theta $        | Vecteur des param√®tres du mod√®le |
| $\theta_j $      | $j $-i√®me param√®tre du mod√®le |
| $\theta^T x^{(i)} $ | Produit scalaire entre $\theta $ et $x^{(i)} $, soit la pr√©diction du mod√®le |
| $m $            | Nombre total d'exemples d'entra√Ænement |
| $x^{(i)} $      | Vecteur des caract√©ristiques de l'exemple $i $ |
| $x_j^{(i)} $    | $j $-i√®me caract√©ristique de l'exemple $i $ |
| $y^{(i)} $      | Valeur r√©elle de sortie pour l'exemple $i $ |
| $h_\theta(x^{(i)}) $ | Pr√©diction du mod√®le pour l'exemple $i $ (√©quivalent √† $\theta^T x^{(i)} $) |
| $\alpha $      | Taux d'apprentissage (learning rate) |

<br>
<br>

---
### Vecteur Gradient du MSE

Pour calculer
**Vecteur Gradient du MSE**
$$
\nabla_\theta MSE = \frac{2}{m} X^T (X\theta - y)
$$




| Symbole                    | Signification |
|----------------------------|--------------|
| $ \nabla_\theta MSE $      | Gradient du MSE (vecteur des d√©riv√©es partielles) |
| $ X $                      | Matrice des caract√©ristiques de taille $ m \times n $ |
| $ y $                      | Vecteur des valeurs r√©elles de taille $ m \times 1 $ |
| $ \theta $                 | Vecteur des param√®tres du mod√®le de taille $ n \times 1 $ |
| $ X\theta $                | Pr√©dictions du mod√®le (produit matriciel) de taille $ m \times 1 $ |
| $ X^T $                    | Transpos√©e de la matrice $ X $, de taille $ n \times m $ |
| $ X^T (X\theta - y) $      | Gradient du MSE avant multiplication par $ \frac{2}{m} $ |
| $ \alpha $                 | Taux d'apprentissage (learning rate) |


<br>
[Retour √† l'index](#contexte-du-projet)


