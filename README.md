# what is machine learning

## Recherches et documentation

0. [Lexique](#Lexique)
1. [Science des donn√©es](#science-des-donn√©es)
2. [Apprentissage automatique ](#apprentissage-automatique)
3. [Apprentissage supervis√©](#apprentissage-supervis√©)
4. [Apprentissage non supervis√©](#apprentissage-non-supervis√©)
5. [Classification supervis√©e](#classification-supervis√©e)
6. [Classification non supervis√©e](#classification-non-supervis√©e)
7. [Donn√©es d'entra√Ænement, de test, de validation](#donn√©es-dentra√Ænement-de-test-de-validation)
8. [Validation crois√©e](#validation-crois√©e)
9. [Corr√©lation lin√©aire (de pearson) entre deux variables](#corr√©lation-lin√©aire-de-pearson-entre-deux-variables)
10. [Fonction de co√ªt](#fonction-de-co√ªt)
11. [R√©gression](#regression)
12. [Descente de gradient](#descente-de-gradient)
13. [Apprentissage profond](#apprentissage-profond)


## Sources
<div class="encadre">

   - **Machine learning avec Scikit-Learn**
   Aur√©lien G√©ron, editions Dunod O'reilly
   2017
   - **Machine learning : les fondamentaux**<br> *Exploiter des donn√©es structur√©es en Python*
   Harrison Matt, √©ditions O'Reilly Media
   2020
   - [StatQuest](https://statquest.org/video-index/) et sa [cha√Æne youtube](https://www.youtube.com/watch?v=fSytzGwwBVw&list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF&index=3)
   - [MachineLearnia](https://www.machinelearnia.com/) et sa [cha√Æne youtube](https://www.youtube.com/@MachineLearnia)
   - [Datatab.fr](https://datatab.fr/tutorial/regression)
   - [Universit√© d'Angers](math.univ-angers.fr/labatte/enseignement/master/classificationsupervisee.pdf)
   - [IBM](https://www.ibm.com/fr-fr/topics/machine-learning)
   - [CNIL](https://www.cnil.fr/fr/definition/apprentissage-automatique)
   - [ekinox.io](https://blog.ekinox.io/ml/normalisation-series-temporelles)
   - [wikipedia](https://fr.wikipedia.org/wiki/Apprentissage_automatique)

</div>

## Lexique :

|||
|:--------------------|:--|
|**attribut**| type de donn√©e ( ex : *kilom√©trage* )|
|**caract√©ristique**<br><font color="orange">Feature</font><br> **variable explicative**| un attribut **et** sa valeur ( ex : *kilom√©trage = 58 000 km )*|
|**variable √† expliquer**<br><font color="orange">Target</font>| √©tiquette|
|**variable qualitative**|Aussi appel√© **variable cat√©gorielle**<br>Ne peut prendre qu'un nombre fini de valeurs, appel√©es **modalit√©es**<br>|
|**intercept** <br> **$\theta_0 $** <br> **terme constant**|dans une √©quation de r√©gression lin√©aire <br> valeur de la variable √† expliquer lorsque toutes les variables explicatives sont √©gales √† z√©ro. <br> Point d'intersection avec l'axe des ordonn√©es.|
|**biais**| synonyme d'intercept dans les mod√®les de r√©gression.<br> Repr√©sente l'ajustement constant n√©cessaire pour mieux pr√©dire la variable √† expliquer, ind√©pendamment des variables explicatives.<br> Dans un mod√®le d'apprentissage automatique, c'est la valeur qui est ajout√©e avant d'appliquer les coefficients aux variables explicatives.|
|**hyperparam√®tre**|param√®tre de l'algorithme d'apprentissage (et non du mod√®le)<br>Permet de contr√¥ler le niveau de **r√©gularisation** durant l'apprentissage (il doit √™tre d√©fini avant, et rester constant)|

**Intercept et biais** sont souvent utilis√©s de mani√®re interchangeable, en particulier dans le contexte de mod√®les de r√©gression, o√π le biais ajuste la sortie avant d'appliquer les coefficients aux variables explicatives.


[Retour √† l'index](#recherche-et-documentation)



## Science des donn√©es
Ou comment g√©n√©rer du sens √† partir de donn√©es - *Faire parler les donn√©es*.
<p align="center">
<img src="img/dataScience.png" alt="data_science">
</p>
Consid√©r√©e comme un nom alternatif pour les statistiques dans les ann√©es 60, la science des donn√©es devient une discipline √† part enti√®re √† la fin des ann√©es 90 avec le boom de l'informatique.<br>
<br>
Elle s'articule autour de la donn√©e :

- conception.
- collecte.
- analyse.

L'objet de cette science est l'√©tude et l'analyse des donn√©es afin d'en extraire des informations pertinentes pour les entreprises.

Elle adopte une approche pluridisciplinaire, m√™lant des concepts et des m√©thodes issus des **math√©matiques**, des **statistiques**, de l'**intelligence artificielle** et de l'**informatique**.

L'objectif est d'examiner de vastes ensembles de donn√©es pour r√©pondre √† des questions cl√©s telles que :
- Que s'est-il pass√© ?
- Pourquoi cela s'est-il produit ?
- Que va-t-il se passer ?
- Quelles actions peut-on entreprendre sur la base de ces r√©sultats ?

4 formes d'analyse principale se d√©gagent :
1. **Analyse descriptive**
visualisation de donn√©es
2. **Analyse diagnostique**
exploration, transformation, corr√©lation...
3. **Analyse pr√©dictive**
machine learning, la pr√©diction, la comparaison de mod√®les et la mod√©lisation pr√©dictive.
4. **Analyse prescriptive**
suite logique et proactive de l'analyse pr√©dictive
<br>

[Retour √† l'index](#recherche-et-documentation)
<br>

## Apprentissage automatique
L'art de programmer des ordinateurs de sorte qu'ils puissent apprendre √† partir de donn√©es

On consid√®re qu'un ordinateur "apprend" s'il am√©liore sa **[performance](#fonction-de-co√ªt)** lors de l'ex√©cution d'une **t√¢che** au fur et √† mesure de son **exp√©rience**.



### Il existe 2 grandes familles d'apprentissage automatique :
#### <font color="orange">La classification</font> - pr√©dire des classes
Pr√©dire une cat√©gorie ou une √©tiquette √† partir des caract√©ristiques des donn√©es d'entr√©e.

**exemple :**  filtre de spam √† partir d'e-mail accompagn√©s de leur classe (normal/spam) 

#### <font color="orange">La r√©gression</font> - pr√©dire des valeurs
Pr√©dit une valeur num√©rique **cible (target)** √† partir des valeurs **caract√©ristiques (feature)** d'attributs ou de variables d'une observation

**exemple :** pr√©dire le prix d'une voiture en fonction de son age, de son kilom√©trage, etc...

### Mode de g√©n√©ralisation
On peut aussi cat√©goriser les syst√®me de machine learning selon leur mode de g√©n√©ralisation  :
<font color="orange">Apprentissage √† partir d'observation</font> - **Instance based learning**<br> Le syst√®me g√©n√©ralise √† de nouveaux cas en utilisant une mesure de similarit√©

<font color="orange">Apprentissage √† partir d'un mod√®le</font> <br>
Construit un mod√®le √† partir des exemples.
Ce mod√®le est ensuite utilis√© pour les pr√©dictions


## Apprentissage supervis√©
Les donn√©es d'entrainement fournies √† l'algorithme comportent des **√©tiquettes** qui indiquent le r√©sultat voulu.
Les donn√©es sont caract√©ris√© par des variables X (**features**), et annot√© d'une variable y (**label/target**)
<p align="center">
  <img src="img/etiquette.png" alt="√©tiquette">
</p>

L'objectif de l'algorithme est d'apprendre √† faire correspondre les entr√©es aux sorties afin de pouvoir pr√©dire l'√©tiquette correcte pour de nouvelles donn√©es jamais vues.
<p align="center">
  <img src="img/apprentissage_supervise.png" alt="apprantissage supervis√©">
</p>

[Retour √† l'index](#recherche-et-documentation)


## Apprentissage non supervis√©
Les donn√©es d'entrainement ne comportent **pas d'√©tiquettes**.
L'algorithme n'a donc pas d'informations sur le r√©sultat attendu.
Il explore les donn√©es pour y d√©couvrir des structures, des motifs ou des relations cach√©es sans qu'une sortie sp√©cifique ne lui soit fournie.
Il tente d'organiser les donn√©es selon leurs similarit√©s ou diff√©rences.

|                 | Apprentissage supervis√©            | Apprentissage non supervis√©           |
|-----------------------|------------------------------------|--------------------------------------|
| Donn√©es               | √âtiquet√©es                         | Non √©tiquet√©es                      |
| Objectif              | Pr√©dire une sortie                 | D√©couvrir des structures            |
| Types de probl√®mes    | Classification, r√©gression         | Clustering, r√©duction de dimensionnalit√© |
| Exemples typiques     | D√©tection de spam, pr√©vision des ventes | Segmentation de clients, d√©tection d'anomalies |



[Retour √† l'index](#recherche-et-documentation)
<br>

## Classification / R√©gression

### Classification

Pr√©diction d'une variable  **qualitative/discr√®te** 
 
### Regression
 
Pr√©diction d'une variable **quantitative/continue**



## Classification supervis√©e

- **On dispose d'observations d√©j√† class√©s**
- **On veut classer une nouvelle observation, lui attribuer une √©tiquette**

La classification supervis√©e repose sur des algorithmes qui apprennent, √† partir d‚Äôun ensemble de donn√©es d‚Äôentra√Ænement √©tiquet√©es, √† associer chaque nouvelle observation √† l‚Äôune des cat√©gories d√©finies.

<p align="center">
  <img src="img/classification_supervise.png" alt="classification supervis√©e">
</p>
Le mod√®le identifie des motifs et des relations entre les variables explicatives (features) et les classes cibles, puis il formalise ces relations sous forme de r√®gles de d√©cision.

Ces r√®gles permettent ainsi de classer automatiquement de nouvelles observations en se basant sur leurs caract√©ristiques.

**Exemple :** un mod√®le de classification des emails peut apprendre que la pr√©sence de certains mots-cl√©s, la fr√©quence d‚Äôenvoi ou l‚Äôadresse de l‚Äôexp√©diteur sont des crit√®res pertinents pour distinguer un spam d‚Äôun email l√©gitime.


<br>

[Retour √† l'index](#recherche-et-documentation)

<br>

## Classification non supervis√©e

La classification non supervis√©e est une technique d'apprentissage automatique utilis√©e lorsque les donn√©es ne sont pas accompagn√©es de labels ou d'√©tiquettes pr√©existantes.

L'objectif est d'**identifier des structures** cach√©es **ou des regroupements naturels** dans les donn√©es.

1. On dispose d'**√©l√©ments non class√©s**
   les mots d'un texte ou les clients d'un site e-commerce sans information pr√©alable sur leurs cat√©gories.
<br>

2. On cherche √† les **regrouper en classes en se basant sur leurs similitudes**
  par exemple :
    - les mots ayant des contextes d'utilisation proches
    - les clients ayant des comportements d'achat similaires.
<br>

3. Si l'algorithme attribue la m√™me √©tiquette √† plusieurs √©l√©ments.
   Ils sont suppos√©s √™tre en rapport avec une m√™me th√©matique ou un m√™me comportement, formant ainsi des clusters (groupes).

| 1 | 2 | 3 |
|--------|---------------|----------------|
|![Classification non supervis√©e](img/classification_non_supervise1.png)|![Classification non supervis√©e 2](img/classification_non_supervise2.png)|![Classification non supervis√©e3](img/classification_non_supervise3.png)|

**Exemples courants :**
- Regrouper des articles de presse selon leurs sujets (politique, sport, technologie...).
- Segmenter une client√®le selon ses habitudes d'achat pour du marketing cibl√©.
<br>

[Retour √† l'index](#recherche-et-documentation)
<br>



## Donn√©es d'entra√Ænement, de test, de validation

Apr√®s les phases de collecte, de nettoyage et de pr√©paration des donn√©es :
- recherche de correlations entre les variables
- gestion des variables quantitative (stratification, normalisation, ...)
- gestion des variables qualitative (encodage, onehot encoding, ...)
- combinaison de variables (cr√©ation de nouvelles caract√©ristiques, feature engineering).

Vient la phase de l'**entrainement du mod√®le**.
supervis√© ou non supervis√© selon que les donn√©es contiennent ou non des √©tiquettes (labels)
Il permet d'ajuster le mod√®le choisi aux donn√©es dans le but de faire des pr√©dictions ou de la classification sur de nouvelles donn√©es

### Entrainement

Entrainer un mod√®le consiste √† d√©finir ses param√®tres de telle sorte qu'ils s'ajustent au mieux au jeu d'entrainement

La [Fonction de co√ªt](#fonction-de-co√ªt) permet de mesurer si le mod√®le s'ajuste bien aux donn√©e d'entrainement (ou pas).
Pour un mod√®le de **Regression** les fonctions de co√ªt usuelles sont :
- **RMSE** racine carr√©e des erreurs quadratique moyenne -(root mean square error)
- **MSE** erreur quadratique moyenne - (mean square error)

Pour entrainer un mod√®le de r√©gression lin√©aire, il faut trouver le vecteur $\theta$ qui minimise la fonction de co√ªt.

#### Entrainement - M√©thode analytique
Calcul les valeurs des param√®tres du mod√®le qui donnent le meilleur r√©sultat sur le jeu d'entrainement
(qui minimise la fonction de co√ªt)

#### Entrainement - Descente de gradient
ou *Gradient Descent* en anglais<br>
Optimisation it√©rative qui modifie graduellement les param√®tres du mod√®le pour minimiser la fonction de co√ªt sur le jeu d'entrainement<br>
**Converge au final vers le m√™me jeu de param√®tres que la m√©thode analytique** ou une approximation du minimum global si le mod√®le n'est pas convexe.



### validation
L'objectif est d'ajuster et d'optimiser le mod√®le.<br>
On utilise un jeu de validation distinct du jeu d'entrainement (validation simple) ou la cross validation

- Optimisation des hyperparam√®tres du mod√®le pour am√©liorer ses performances.
- d√©tecter d'√©ventuels probl√®mes
- D√©tecter le surajustement : un mod√®le trop complexe m√©morise les donn√©es au lieu d'apprendre leurs tendances.
- D√©tecter le sous-ajustement : un mod√®le trop simple passe √† c√¥t√© des structures importantes.
- Optimiser les performances : tester diff√©rentes configurations pour maximiser les r√©sultats.
- G√©n√©ralisation : le jeu de validation permet d'estimer comment le mod√®le se comportera sur des donn√©es r√©elles et non vues auparavant.

#### Surajustement
<font color="orange">**Overfitting**</font> : le mod√®le apprend trop bien les d√©tails et le bruit des donn√©es d'entra√Ænement, ce qui nuit √† sa capacit√© √† g√©n√©raliser.<br>
Solutions possible :
- simplifier le mod√®le, moins de param√®tres
- r√©duire le nombre d'attributs des donn√©es d"entrainement
- imposer des contraintes au mod√®le avec un hyperparam√®tre (**r√©gularisation**)
- utiliser plus de donn√©es d'apprentissage
- r√©duire le bruit des donn√©es (supprimer les donn√©es ab√©rantes, les erreurs)


#### Sous-ajustement
<font color="orange">**Underfitting**</font> : le mod√®le est trop simple et ne capte pas la structure sous-jacente des donn√©es.<br>
Solutions possible :
- Choisir un mod√®le plus puissant, avec plus de param√®tres
- Fournir de meilleurs variables √† l'algorithme d'apprentissage
- r√©duire les contraintes sur le mod√®le (hyperparam√®tre de r√©gularisation)

![Ajustement](img/fitting.webp)

### test
La phase de test est l'√©tape finale, elle consiste √† √©valuer les performances du mod√®le sur un jeu de donn√©es qui n'a pas √©t√© utilis√© pendant l'entra√Ænement ou la validation.<br>
Le jeu de test ne doit jamais √™tre utilis√© pour ajuster le mod√®le. Il sert uniquement √† mesurer sa performance finale.
Cela permet d'obtenir une estimation objective de la capacit√© du mod√®le √† g√©n√©raliser ses pr√©dictions sur de nouvelles donn√©es.

**√âvaluation des performances :**
On compare les pr√©dictions du mod√®le avec les valeurs du jeu de test.

**M√©triques courantes pour √©valuer les performances :**
**classification**
- Pr√©cision (Accuracy) : proportion de pr√©dictions correctes.
- Rappel (Recall) : capacit√© du mod√®le √† identifier les √©l√©ments positifs.
- F1-score : moyenne harmonique entre la pr√©cision et le rappel.
**r√©gression**
- Erreur quadratique moyenne (MSE).
- RMSE.
- R¬≤ (coefficient de d√©termination).

**Importance du test :**
- Identifier les biais et faiblesses du mod√®le 
- V√©rifier sa capacit√© √† g√©n√©raliser.

Une fois le mod√®le test√©, on ne le modifie plus.


<br>

[Retour √† l'index](#recherche-et-documentation)
<br>

Dans un projet de Machine Learnig, il faut s√©parer les donn√©es :

1. <font color ="orange">Jeu d'entrainement</font> pour ajuster le mod√®le aux donn√©es. Essayer d'avoir l'erreur d'apprentissage la plus faible possible en comparant plusieurs mod√®les avec diff√©rent hyperparam√®trees

2. <font color ="orange">Jeu de test</font> pour √©valuer les performances du mod√®le entrain√©.
Connaitre l'erreur de g√©n√©ralisation des diff√©rents mod√®les pr√©cedement entrain√©s

3. <font color ="orange">Jeu de validation</font> pour faire un test final avec le meilleur mod√®le et les meilleurs hyperparam√®tres.

 
Ces trois √©tapes ‚Äì **entra√Ænement**, **test** et **validation** ‚Äì sont essentielles pour garantir que le mod√®le est fiable et performant avant son d√©ploiement.
<br>
<br>
Il est courant d'avoir recours √† la technique de la [Validation crois√©e](#validation_croisee) pour √©viter de gaspiller des donn√©es d'entrainement dans le jeu de validation :
- le jeu d'entrainement est partag√© en sous-ensembles
- chaque mod√®le est entrain√© sur une combinaison diff√©rente de sous-ensembles
- chaque mod√®le est valid√© sur le sous-ensemble restant
- Le mod√®le s√©lectionn√© est entrain√© sur l'ensemble du jeu d'entrainement
- il est test√© sur le jeu de test√© pour mesurer l'erreur de g√©n√©ralisation.c

## Validation crois√©e
Dans un projet de Machine Learnig, il faut s√©parer les donn√©es :

- un Jeu de donn√©es pour **entrainer** le mod√®le 
- un Jeu de donn√©es pour **tester** le mod√®le entrain√©
- un dernier Jeu pour **valider** le mod√®le sur de nouvelles donn√©es

**<font color="orange">La validation crois√©e</font>**
Consiste en l'utilisation alternative et conjointe des Jeu d'entrainement et de test.
Cela implique d'entrainer/tester le mod√®le plusieurs fois :

1. division du Jeu de donn√© en K sous-ensembles
<br>
2. entrainement puis √©valuation du mod√®le K fois
    - en changeant de combinaison Jeu d'entrainement / Jeu d'√©valuation √† chaque it√©ration
<br>
3. compare les r√©sultats obtenus
<br>

Ainsi, toutes les tranches de donn√©e sont alternativement r√©serv√®es aux test.
Au final, toutes les donn√©es ont servies √† l'entrainement et au test.
Cela permet d'obtenir une estimation plus stable des performances.
N√©cessite l'utilisation d'une [fonction de fitness](#fonction-de-co√ªt)


#### Validation crois√©e avec un dataset divis√© en 4 sous ensemble :

|it√©ration | <font color="blue">entrainement</font> | <font color="orange">test</font>| r√©sultats|
|:------:|:-------------:|:--------------:|:---------------:|
|**1**|![train_4](img/cross_validation_train_4.png)<font color="blue">tranches 2, 3 et 4</font>|  ![test_4](img/cross_validation_test_4.png)<font color="orange">tranche 1</font>|![track_4](img/cross_validation_track_4.png)|
|**2** | <font color="blue">tranches 1, 3 et 4</font>|<font color="orange">tranche 2</font>|![track_3](img/cross_validation_track_3.png)|
|**3** | <font color="blue">tranches 1, 2 et 4</font>|<font color="orange">tranche 3</font>|![track_2](img/cross_validation_track_2.png)|
|**4** | <font color="blue">tranches 1, 2 et 3</font>|<font color="orange">tranche 4</font>|![track_1](img/cross_validation_track_1.png)|



L'id√©al √©tant de faire une **validation crois√©e avec diff√©rent mod√®les** afin de les comparer :
- Logistic regression
- support vector machines
- k-nearest neighbors
- etc...
<p align="center">
  <img src="img/cross_validation_comparaison.png" alt="comparaison des r√©sultats de la cross validation">
</p>


[Retour √† l'index](#recherche-et-documentation)


## Corr√©lation lin√©aire (de Pearson) entre deux variables

La corr√©lation lin√©aire de Pearson mesure l'intensit√© et le sens de la relation lin√©aire entre deux variables quantitatives.

Elle est d√©finie par un coefficient, not√© **r**, avec une **valeur comprise entre -1 et 1 :**
| coefficient r|correlation|signification|
|:--:|:-------:|-----|
|**1**| positive forte| si une des variables augmente, l'autre augmente pareillement|
|**0.3**| positive faible| si une des variables augmente, l'autre augmente moins|
|**0**|Aucune corr√©lation lin√©aire| les variables ne pr√©sentent pas de relation lin√©aire claire|
|**- 1**| n√©gative forte| si une des variables augmente, l'autre diminue pareillement|
|**- 0.3**| n√©gative faible| si une des variables augmente, l'autre diminue moins|


[Formule du coefficient de Pearson](formules.md#coefficient-de-pearson)



<br>

**Ci dessous**, pour des Jeu de donn√©es √† deux variables :
le coefficient de corr√©lation et le nuage de points correspondant
<p align="center">
  <img src="img/correlation.svg" alt="corr√©lation">
</p>

- **2√®me ligne :** coefficients = 1 ou -1  ind√©pendemment de la pente
- **3√®me ligne :** coefficients nuls alors que les variables ne semblent pas ind√©pendantes !
   <font color="orange">relations **non lin√©aires**</font>

<br>
<br>

**Matrice de correlation d'un dataset de 4 variables sur les p√©tales de fleurs iris**
<p align="center">
  <img src="img/matrice_correlation.png" alt="matrice de corr√©lation">
</p>

**<font color="orange">Attention :</font>**
- une corr√©lation forte ne signifie pas n√©cessairement une relation causale
- ne d√©tecte pas les relation non lin√©aires (par ex: si x proche de 0, y augmente)

<br>

[Retour √† l'index](#recherche-et-documentation)
<br>

## Fonction de co√ªt

Mesure de performance qui permet de savoir si le mod√®le est bien parametr√© :
| fonction|Valeur si le mod√®le est bon|
|--------------|-------------|
|de **fitness** (d'adaptation) | √©lev√©e|
| de **co√ªt** | faible|

La **<font color="orange">fonction de co√ªt</font>** quantifie l'**√©cart entre les pr√©dictions du mod√®le et les valeurs r√©elles**.
L'objectif lors de l'entra√Ænement est de minimiser cette fonction pour am√©liorer la pr√©cision du mod√®le.

Diff√©rents types de fonctions de co√ªt existent selon le probl√®me trait√© :

- [**Erreur quadratique moyenne (MSE)**](#regression-lineaire.md) pour les probl√®mes de **r√©gression**
- **Entropie crois√©e** pour les probl√®mes de **classification**
- **Hinge loss** pour les **SVM (machines √† vecteurs de support)**

[Formule MSE](formules.md#MSE)

Un mod√®le bien param√©tr√© aura donc une fonction de co√ªt faible et, inversement, une fonction de fitness √©lev√©e, indiquant une bonne capacit√© du mod√®le √† g√©n√©raliser sur des donn√©es non vues.

#### A noter
<font color ="orange">La fonction de co√ªt MSE du mod√®le de regression lin√©aire</font> est une **fonction convexe (en cloche)**
Elle √† donc <font color ="orange">un minimum global</font> , mais <font color ="orange">pas de minimum local</font>
C'est aussi une fonction continue, sa pente ne varie jamais abruptement.
<br>

[Retour √† l'index](#recherche-et-documentation)
<br>


## R√©gression

En math√©matiques, la r√©gression recouvre plusieurs m√©thodes d‚Äôanalyse statistique permettant d‚Äôapprocher une variable √† partir d‚Äôautres qui lui sont corr√©l√©es.


#### **1. [R√©gression Lin√©aire](#regression-lineaire)**
- Suppose une relation lin√©aire entre les variables.  
- Exemple : Pr√©dire le prix d‚Äôune maison en fonction de sa surface.

#### **2. R√©gression Polynomiale**
- Extension de la r√©gression lin√©aire 
- permet de mod√©liser des relation non lin√©aires en attribuant des puissances aux variables ind√©pendantes.
- Elle utilise plus de param√®tres, ce qui la rend plus flexible, mais √©galement plus sujette au surajustement (overfitting).

#### **3. R√©gression Logistique**  
- Pour des probl√®mes de **classification binaire** (oui/non, 0/1, vrai/faux).  
- La sortie est une probabilit√©, utilis une fonction logistique (sigmo√Øde).  
- Exemple : Pr√©dire si un email est spam ou non.

**Variantes :**
- **R√©gression Logistique Multinomiale** : Pour plus de deux classes.  
- **R√©gression Logistique Ordinale** : Pour des classes ordonn√©es (ex : satisfaction client : "faible", "moyenne", "√©lev√©e").  


#### **4. R√©gression Ridge et Lasso**
- **Ridge Regression** : Ajoute une p√©nalit√© sur les coefficients (r√©gularisation L2) pour √©viter le surapprentissage.  
- **Lasso Regression** : R√©gularisation L1 qui met certains coefficients √† z√©ro (s√©lection de variables).  
- **ElasticNet** : Combinaison de Ridge et Lasso.


#### **5. R√©gression des Moindres Carr√©s Ponder√©s (WLS)**
- Variante de la r√©gression lin√©aire o√π certaines observations ont plus de poids que d'autres.  
- Utilis√©e lorsque la variance des erreurs n'est pas constante (h√©t√©rosc√©dasticit√©).  


#### **6. R√©gression Quantile**
- Au lieu de pr√©dire la moyenne des valeurs cibles, elle pr√©dit un quantile donn√© (ex : m√©diane).  
- Utile lorsque les donn√©es contiennent beaucoup de valeurs extr√™mes (outliers).  


#### **7. R√©gression Poisson**
- Utilis√©e lorsque la variable cible est un **compte** (nombre d'√©v√©nements).  
- Exemple : Nombre de clients arrivant dans un magasin par heure.

#### **8. R√©gression Probit et Tobit**
- **Probit** : Alternative √† la r√©gression logistique pour des probabilit√©s.  
- **Tobit** : Utilis√©e lorsque la variable cible est tronqu√©e (ex : des salaires ne pouvant pas √™tre n√©gatifs).  


#### **9. R√©gression PLS (Partial Least Squares)**
- Variante de la r√©gression lin√©aire utilis√©e quand les variables explicatives sont fortement corr√©l√©es.  


#### **10. R√©gression Support Vector Regression (SVR)**
- Bas√©e sur les **machines √† vecteurs de support (SVM)**.  
- G√®re bien les donn√©es non lin√©aires et les valeurs aberrantes.  


#### **11. R√©gression avec R√©seaux de Neurones (NN)**
- Utilise des architectures de deep learning pour mod√©liser des relations complexes.  
- Exemple : R√©seaux de neurones profonds pour la pr√©vision boursi√®re.  


#### **12. R√©gression Bay√©sienne**
- Int√®gre une approche probabiliste et des distributions de probabilit√© sur les param√®tres du mod√®le.  
- Exemple : Utilis√© en m√©decine pour estimer des risques individuels.  

|||
|-|-| 
|**Donn√©es continues** | R√©gression lin√©aire, polynomiale, Ridge, Lasso, PLS, SVR, NN, Bay√©sienne| 
|**Donn√©es discr√®tes (comptage)** | R√©gression Poisson|
|**Classification binaire/multiclasse** | R√©gression logistique, probit|  
|**Donn√©es avec outliers** | R√©gression quantile|  
|**Corr√©lation entre variables explicatives** | R√©gression PLS, Ridge|  


#### R√©gression lin√©aire  {#regression-lineaire}

[notebook regression_lineaire](regression.ipynb)

Mod√©lisation  par une droite de la **relation** entre une/des **variables ind√©pendantes X** en entr√©e, et une **variable d√©pendante y** en sortie.

Le mod√®le lin√©aire effectue une **pr√©diction `y`** en calculant une somme pond√©r√©e de variables d'entr√©e `X` et ajoute un **terme constant (intercept) $\theta_0$** sans pond√©ration

`y` est une combinaison lin√©aire des features `X` et d'un terme d'erreur qui introduit des impr√©cisions ou de la variabilit√©.



||forme scalaire|forme de somme pond√©r√©e|
|-|:--:|:--:|
|$\hat{y} = $|$\theta_1 x_1 + \dots + \theta_n x_n + \theta_0$|$\sum_{i=0}^{n} \theta_i x_i$|


<br>

|symbole|signification|
|:--:|:--:|
|$\hat{y}$ | valeur pr√©dite|
|$n$ | nombre de variables|
|$\theta_i$ | param√®tre du mod√®le, coefficient|
|$x_i$ | variable explicative|
|$\theta_0$|	Biais/intercept/constante qui n'est pas pond√©r√©e <br> Valeur de `y` lorsque toutes les variables $ùë•_ùëñ$ sont √©gales √† z√©ro|

Peut aussi s'√©crire sous forme [vectorielle ou matricielle](regression_lineaire.md)

<br>

[Retour √† l'index](#recherche-et-documentation)
<br>



## Descente de gradient

La descente de gradient (*Gradient Descent*) est une m√©thode d'entra√Ænement utilis√©e pour optimiser les mod√®les de **r√©gression lin√©aire** et d'autres algorithmes d'apprentissage automatique.  

#### **Principe : Correction progressive des param√®tres**  
L'objectif est de mettre √† jour les param√®tres \( \theta \) du mod√®le afin de **r√©duire la valeur de la fonction co√ªt** sur le jeu d'entra√Ænement.  
Pour ce faire, on ajuste progressivement et simultan√©ment les param√®tres en **suivant la direction oppos√©e au gradient** de la fonction co√ªt.  

<div style="border: 1px solid black; padding: 10px;">
Il existe plusieurs types de descente de gradient :<br>
<ul>
<li><strong>batch (Batch Gradient Descent)</strong><br>mise √† jour des param√®tres apr√®s avoir calcul√© le gradient sur **l‚Äôensemble** des donn√©es d'entra√Ænement.</li>
<li><strong>par mini-lots (Mini-Batch Gradient Descent)</strong><br> mise √† jour apr√®s calcul du gradient sur un **sous-ensemble** al√©atoire (mini-lot) de donn√©es.</li>
<li><strong>stochastique (Stochastic Gradient Descent, SGD)</strong><br> mise √† jour apr√®s chaque **exemple individuel**, ce qui introduit plus de bruit mais peut acc√©l√©rer l‚Äôapprentissage.</li>
</ul>  </div>

<br>


Calcule le gradient de la fonction co√ªt au point $\theta$
Met √† jour les param√®tres en **se d√©pla√ßant dans la direction oppos√©e au gradient** pour minimiser cette fonction.

**Le gradient** est une d√©riv√©e partielle de la fonction co√ªt par rapport aux param√®tres $\theta$, indiquant la direction de la plus forte augmentation.

**vecteur gradient** : lorsqu'il y a plusieurs param√®tres
on calcule la **d√©riv√©e partielle** de la fonction co√ªt de chaque param√®tre.
On appelle ces d√©riv√©es des gradients

**La descente de gradient** calcule le gradient de la fonction co√ªt au point $\theta_i$, puis progresse dans la direction oppos√©e au gradient.


Pour minimiser la fonction co√ªt, on se d√©place dans la direction oppos√©e au gradient.



- **Gradient** : c'est la **d√©riv√©e partielle** de la fonction co√ªt par rapport √† un param√®tre \( \theta \), indiquant la **direction de la plus forte augmentation**.  
- **Vecteur gradient** : lorsque plusieurs param√®tres sont pr√©sents, la fonction co√ªt d√©pend de plusieurs variables.  
  - On calcule alors les **d√©riv√©es partielles** de la fonction co√ªt pour chaque param√®tre.  
  - L‚Äôensemble de ces d√©riv√©es forme un **vecteur gradient**, qui est utilis√© pour ajuster tous les param√®tres simultan√©ment.  

---
### **√âtapes de la descente de gradient** :
1. Calcul du **gradient de la fonction co√ªt** au point $\theta$, choisi initialement (souvent al√©atoirement).  
2. progression en direction du gradient descendant en fonction du pas : hyperparam√®tre `learning_rate`
Mise √† jour des param√®tres en suivant la r√®gle : 

   $$\theta \leftarrow \theta - \text{learning rate} \times \nabla J(\theta)$$

  |||
  |-|-|
  |$\nabla J(\theta)$ |gradient de la fonction co√ªt |
  |`learning_rate` | **hyperparam√®tre** qui contr√¥le la vitesse d'apprentissage.|

3. R√©p√©tition du processus jusqu'√† convergence,<br> **lorsque la variation de la fonction co√ªt devient n√©gligeable**<br>ou qu'un nombre maximal d'it√©rations est atteint.
 ---


### Exemple d'une descente de gradient
- Pour une descente de gradient appliqu√©e √† une fonction de type **y = aX + b**
- **Fonction de co√ªt :**
Le r√©siduel est la diff√©rence entre la valeur r√©elle (target) d'une observation et la valeur pr√©dite par le mod√®le.
**SSR** = somme des r√©sidus pour un mod√®le donn√© (c'est ce qu'on visualise ci-dessous). 

#### 1Ô∏è‚É£ Initialisation des param√®tres  
- Choisir des valeurs initiales pour **a** et **b** (souvent al√©atoires ou √† z√©ro).  
- D√©finir un **taux d‚Äôapprentissage (learning rate)** qui contr√¥le la vitesse de mise √† jour des param√®tres.  

#### 2Ô∏è‚É£ Calcul des pr√©dictions et de l'erreur   
- Pour chaque point de donn√©es (X, y), calculer la valeur pr√©dite **≈∑ = aX + b**. 
- Comparer chaque pr√©diction **≈∑** avec la valeur r√©elle **y**.  
- Calculer l‚Äôerreur (√©cart entre la pr√©diction et la vraie valeur). 

#### 3Ô∏è‚É£ Calcul des gradients  
- D√©terminer **dans quelle direction** ajuster **a** et **b** pour r√©duire l‚Äôerreur.  
- Cela revient √† mesurer l‚Äôimpact d‚Äôune petite variation de **a** et **b** sur l‚Äôerreur globale.  

#### 4Ô∏è‚É£ Mise √† jour des param√®tres  
- Modifier **a** et **b** dans la direction qui r√©duit l‚Äôerreur, en fonction du taux d‚Äôapprentissage.  

#### 5Ô∏è‚É£  R√©p√©tition jusqu'√† convergence  
- R√©p√©ter les √©tapes 2 √† 5 jusqu‚Äô√† ce que les mises √† jour deviennent tr√®s petites (l‚Äôalgorithme converge).  
- Si n√©cessaire, ajuster le **taux d‚Äôapprentissage** pour √©viter des oscillations ou une descente trop lente.  

Apr√®s plusieurs it√©rations, **a** et **b** seront ajust√©s pour minimiser l‚Äôerreur, donnant la meilleure droite de r√©gression possible.

### Exemple de descente de gradient

||fonction de type `y  = aX + b`|
|:-:|:-|
|`y`|pr√©diction - target|
|`a`|pente - slope - coefficient|
|`X`|vecteur des valeurs - feature|
|`b`| `intercept` - valeur `y` de la pente quand elle coupe l'axe des ordonn√©es y<br> (x = 0) |

#### Sur un seul param√®tre - pour bien comprendre le fonctionnement

**Etapes :**
- On choisi la Sum of Square Residuals comme fonction de co√ªt
- calcul la d√©riv√©e de la fonction de co√ªt
- `intercept` = 0 comme valeur de d√©part
- calcul de la d√©riv√© quand `intercept` = 0
- calcul du pas en cons√©quence
- calcul d'un nouvel `intercept`
- calcul de la d√©riv√© avec le nouvel `intercept`
- bis r√©p√©tita jusqu'√† ce que la pas approche de 0

Si :
1. on connait la `pente` et l'`intercept`:
  - `a` = 0,64
  - `b` ou `intercept` = 0 ( choisis al√©atoirement)
<br>
2. Alors, on peut tracer <font color="green">la ligne qui passe par `b` ou `intercept`, c'est √† dire par `0` dans cet exemple</font>
<br>
3. et donc calculer le `MSR`<br>le carr√© des √©carts entre les ordonn√©es `y`(target) des valeurs du jeux d'entrainement et les <font color="green">valeurs y de la ligne</font>
**Mean Square Residuals** est une mesure interm√©diaire qui guide l'optimisation.

 <br>
4. Tracer sur un le graphe de droite le <font color="red">point de coordonn√©es</font> :
  - en abscisse `x` : `intercept`  (donc 0, que l'on a choisi pr√©c√©dement)
  - en ordonn√©e `y` : `residual` (que l'on vient de calculer)<br>

|Graphe de gauche <br> Jeu d'entrainement|Graphe de droite <br> Mean Square Residuals|
|:--|:--|
|<font color="green">droite y = aX +b</font> <br>`ordonn√©e` = `intercept`ou `b (pour x = 0)` = 0|`abscisse x` = `intercept` = 0 <br> `ordonn√©e y` = somme des `residuals`|

<img src="img/gradient_descent/regression_1.png"/>

<br>
<br>

**On r√©p√®te l'op√©ration avec**
`pas` = `d√©riv√©e` * `learning_rate`
`nouveaux intercept` = `intercept` - `pas` = 0,25

|Jeu d'entrainement|Mean Square Residuals|
|:--|:--|
|<font color="green">droite y = aX +b</font> <br>`ordonn√©e` = `intercept`ou `b (pour x = 0)` = 0.25|`abscisse x` = `intercept` = 0.25 <br> `ordonn√©e y` = somme des `residuals`|

<font color="green">Graphe de gauche</font>, `y` = 0.25 pour `x`= 0
<font color="red">Graphe de droite</font>, `x` = 0.25, `y` = somme des `residual`
|||
|-|-|
|**`intercept`** = intersection de  la droite avec l'axe des ordonn√©es<br>`y` pour `x` = 0|**`intercept` = 0,3**<img src="img/gradient_descent/regression_2.png"/>|
|**`intercept` = 0,5**><img src="img/gradient_descent/regression_3.png"/>|**`intercept` = 0,9**<br><img src="img/gradient_descent/regression_4.png"/>|
|**`intercept` = 1**<img src="img/gradient_descent/regression_5.png"/>|**`intercept` = 1,3**<br><img src="img/gradient_descent/regression_6.png"/>|
|**`intercept` = 1,5**<img src="img/gradient_descent/regression_7.png"/>|**`intercept` = 1,85**<br>  <img src="img/gradient_descent/regression_8.png"/>|


### Sur tous les param√®tres simultan√©ment

En pratique, l'algorithme de descente de gradient modifie tous les param√®tres √† chaque it√©ration
Exemple de descente de gradient sur 2 param√®tres simultan√©ment: `pente`et `intercept`
<img src="img/gradient_descent/gd_2_parametres.png">

**Calcul de la taille du pas entre chaque it√©ration :**
Le pas (ou taux de mise √† jour) entre chaque it√©ration dans la descente de gradient est influenc√© par la pente de la fonction de co√ªt et le learning rate (taux d'apprentissage).

La pente de la descente de gradient, correspond √† la d√©riv√©e partielle de la fonction de co√ªt par rapport aux param√®tres

**pas = pente de la d√©riv√©e de la descente de gradient * learning_rate**

**La pente de la fonction de co√ªt est raide** (la d√©riv√©e est grande)
 un grand pas est n√©cessaire pour faire un grand ajustement.

**La pente est plate** (d√©riv√©e petite)
un petit pas est pr√©f√©rable pour √©viter de trop ajuster le param√®tre et risquer de diverger

**La decente de gradient s'arr√™te quand le pas (et la pente) s'approche de 0**
<br>
Diff√©rent pas d'une descente de gradient de fonction convexe (type fcnction MSE)

![learning rate](img/learning_rate.jpg)

*La fonction de co√ªt MSE est convexe, elle √† donc un minimum global mais pas de minimum local, pas de variation abrupte de pente.*

Le pas pour la mise √† jour des param√®tres √† chaque it√©ration est calcul√© comme suit :
$$
\text{nouveau pas} = \text{pas actuel} - \text{learning rate} \times \frac{\partial \text{MSR}}{\partial \text{param√®tre (ici intercept)}}$$


Quand la pente de la d√©riv√© de la descente de gradient s'approche de 0, on s'approche d'un minimum

### Calcul de la d√©riv√©e partielle
√Ä chaque it√©ration de la descente de gradient :

1. **Calcul du carr√© des r√©sidus**
calcule l'erreur pour chaque observation du jeu d'entra√Ænement
On aditionne le carr√© de l'erreur de chaque observation

2. **Calcul de la Mean Square Residual (MSR)** : On fait la moyenne de ces carr√©s des r√©sidus pour l'ensemble du jeu d'entra√Ænement. ( la moyenne des erreurs quadratiques).

3. **Calcul des d√©riv√©es partielles** : Ensuite, on calcule les d√©riv√©es partielles de la **MSR** par rapport aux param√®tres du mod√®le
Ces d√©riv√©es nous indiquent dans quelle direction et de combien chaque param√®tre doit √™tre ajust√© pour minimiser l'erreur.
On ajuste simultan√©ment tous les param√®tres pendant chaque it√©ration de la descente de gradient.

La d√©riv√©e partielle de la **MSR** par rapport √† \(a\) ou \(b\) nous dit comment ajuster ces param√®tres pour r√©duire l'erreur du mod√®le.

Ainsi, en calculant les d√©riv√©es partielles pour chaque param√®tre, nous savons comment modifier progressivement les valeurs de \(a\) et \(b\) pour "descendre" le long de la pente du gradient et minimiser la **MSR**. Ce processus continue jusqu'√† ce que l'erreur soit aussi faible que possible, indiquant que nous avons trouv√© les param√®tres optimaux pour le mod√®le.

<br>

<font color ="orange">Pour une descente de gradient, toutes les variables doivent avoir la m√™me echelle, sinon la convergence sera plus lente</font>

![Avec et sans normalisation des variable](img/gd_normalize.png)


## Apprentissage profond

<p align="center">
   <img src ="img/deep_learning.png" alt ="deep learning">
</p>
Proc√©d√© d‚Äôapprentissage automatique utilisant des [r√©seaux de neurones](./reseaux_neurones.md)


 compos√© de nombreuses couches cach√©es et des algorithmes avec de tr√®s nombreux param√®tres.
Ce proc√©d√© requi√®re une grande quantit√© de donn√©es afin d‚Äô√™tre entra√Æn√©.

<p align="center">
  <img src="img/reseauNeurones.png" alt="reseau de neurones">
</p>

A permis des progr√®s importants et rapides :
- analyse du signal sonore, reconnaissance faciale
- analyse du signal visuel, reconnaissance vocale
- le traitement automatis√© du langage

Le d√©veloppement de l'apprentissage profond √† √©t√© rendu possible par des investissements priv√©s et publics importants, notamment de la part des GAFAM, durant les ann√©es 2000.
<br>

[Retour √† l'index](#recherche-et-documentation)
<br>
