# Index

- [Mean Square Residuals](#mean-square-residuals)
- [MSE (Mean Squared Error)](#mse)
- [DÃ©rivÃ©e partielle par rapport Ã  un paramÃ¨tre](#derivÃ©e-partielle-par-rapport-Ã -un-paramÃ¨tre-theta_j)
- [DÃ©rivÃ©e partielle](#derivÃ©e-partielle)
- [Vecteur Gradient du MSE](#vecteur-gradient-du-mse)
- [Coefficient de Pearson](#coefficient-de-pearson)

---
|symbole|signification|
|:--:|:--------|
|m|Nombre d'observation du jeu de donnÃ©e|
|$xi$|Vecteur  constituÃ© des valeurs de des variables (hors Ã©tiquette) pour la iÃ¨me observation|
|$X$ |Matrice contenant toutes les valeurs des toutes les variable (hors Ã©tiquette) du jeu de donnÃ©e|
|h|HypothÃ¨se, fonction de prÃ©diction|
|$\hat{y}$|y chapeau, valeur prÃ©dite, retournÃ©e par $h(x^i)$|
|T|TransposÃ©e|


En algÃ¨bre linÃ©aire, par convention, un vecteur est gÃ©nÃ©ralement considÃ©rÃ© comme un vecteur colonne.
|$\textbf{Vecteur } \boldsymbol{x}^i$|$\textbf{TransposÃ©e } (\boldsymbol{x}^i)^T$|
|:--:|:--------|
|![vecteur colonne](img/vecteur_colonne.svg)|![vecterur transposÃ©](img/vecteur_transpose.svg)|


Matrice $\boldsymbol{X}$, constituÃ©e de m vecteurs colonnes, chacun transposÃ© en vecteur ligne
![vecteur colonne](img/matrice.png)
<!-- $$
X = 
\begin{pmatrix} (\boldsymbol{x}^1)^T \\ (\boldsymbol{x}^2)^T \\ (\boldsymbol{x}^{...})^T \\ (\boldsymbol{x}^{m})^T \end{pmatrix} =  
\begin{pmatrix} -11 & 45 & 62 & 13 \\ \cdot & \cdot & \cdot & \cdot \\ \cdot & \cdot & \cdot & \cdot \\ \cdot & \cdot & \cdot & \cdot  \end{pmatrix}
$$-->

### Mean Square Residuals - RÃ©sidu Quadratique Moyen
$$
MSR(\theta) = \frac{1}{m} \sum_{i=1}^{m} (\theta^T x^{(i)} - y^{(i)})^2
$$

$$
\begin{array}{|c|c|}
\hline
\textbf{Symbole} & \textbf{Signification} \\
\hline
m & \text{Nombre total d'exemples dans l'ensemble d'entraÃ®nement} \\
x^{(i)} & \text{Vecteur des caractÃ©ristiques de l'exemple } i \\
\theta & \text{Vecteur des paramÃ¨tres du modÃ¨le} \\
\theta^T x^{(i)} \text{ ou } h (x^{(i)}) & \text{PrÃ©diction du modÃ¨le pour } x^{(i)} \\
y^{(i)} & \text{Valeur rÃ©elle associÃ©e Ã  } x^{(i)} \\
(\theta^T x^{(i)} - y^{(i)})^2 & \text{Erreur quadratique pour un exemple donnÃ©} \\
\hline
\end{array}
$$

### Mean Square Error - Erreure Quadratique moyenne
**Fonction de coÃ»t  pour le modÃ¨le de rÃ©gression linÃ©aire**

Voir la [fonction de coÃ»t](#regression-lineaire.md) du modÃ¨le de regression linÃ©aire

Peut s'Ã©crire de plusieurs maniÃ¨res :<br>
$MSE(X, h_\theta)$, pour montrer que le modÃ¨le est paramÃ©trÃ© par le vecteur $\theta$<br>$MSE(X, h)$<br>
$MSE(\theta)$ pour simplifier :<br>

![MSE](img/MSE.png)
<!--$$
MSE(X, h_\theta) = \frac{1}{m} \sum_{i=1}^{m} \left( \theta^T x^{(i)} - y^{(i)} \right)^2
$$-->

S'Ã©crit aussi

$$J(\theta) = \frac{1}{m} \sum_{i=1}^{m} \left( h_\theta(x^{(i)}) - y^{(i)} \right)^2$$


|symbole|signification|
|:--:|:--------|
|$m$ | nombre total d'exemples dans l'ensemble d'entraÃ®nement.|
|$ğ‘¥(ğ‘–)$  | vecteur des caractÃ©ristiques de l'exemple ğ‘–|
|$ğœƒ$ | vecteur des paramÃ¨tres du modÃ¨le.|
|$ğœƒğ‘‡ğ‘¥(ğ‘–)$ <font color = "orange">ou</font> $h (x^{(i)})$ | prÃ©diction du modÃ¨le pour $ğ‘¥(ğ‘–)$|
|$y(i)$|valeur rÃ©elle associÃ©e Ã  $ğ‘¥_i$|
|$(\theta^T x^{(i)} - y^{(i)})^2$|erreur quadratique pour un exemple donnÃ©|

---
## DÃ©rivÃ©e partielle par rapport Ã  un paramÃ¨tre $\theta_j$

$$\frac{\partial J(\theta)}{\partial \theta_j} = \frac{1}{m} \sum_{i=1}^{m} \left( h_\theta(x^{(i)}) - y^{(i)} \right) x_j^{(i)}$$


## DÃ©rivÃ©e partielle
On note $â„ğœƒ(x^{(  i)})=ğœƒ^ğ‘‡ğ‘¥^{(ğ‘–)}$<br><br>
Donc la dÃ©rivÃ©e partielle du MSE par rapport Ã  $\theta_j$  est :


$$
\frac{\partial MSE}{\partial \theta_j} = \frac{1}{m} \sum_{i=1}^{m}2 \left( \theta^T x^{(i)} - y^{(i)} \right) x_j^{(i)}
$$

DÃ©rivÃ©e partielle par rapport Ã  $\theta_j$ simplifiÃ©e

$$
\frac{\partial MSE}{\partial \theta_j} = \frac{2}{m} \sum_{i=1}^{m} \left( \theta^T x^{(i)} - y^{(i)} \right) x_j^{(i)}
$$




| Symbole               | Signification |
|-----------------------|--------------|
| $MSE(X, h_\theta) $  | Erreur quadratique moyenne (Mean Squared Error) |
| $\theta $        | Vecteur des paramÃ¨tres du modÃ¨le |
| $\theta_j $      | $j $-iÃ¨me paramÃ¨tre du modÃ¨le |
| $\theta^T x^{(i)} $ | Produit scalaire entre $\theta $ et $x^{(i)} $, soit la prÃ©diction du modÃ¨le |
| $m $            | Nombre total d'exemples d'entraÃ®nement |
| $x^{(i)} $      | Vecteur des caractÃ©ristiques de l'exemple $i $ |
| $x_j^{(i)} $    | $j $-iÃ¨me caractÃ©ristique de l'exemple $i $ |
| $y^{(i)} $      | Valeur rÃ©elle de sortie pour l'exemple $i $ |
| $h_\theta(x^{(i)}) $ | PrÃ©diction du modÃ¨le pour l'exemple $i $ (Ã©quivalent Ã  $\theta^T x^{(i)} $) |
| $\alpha $      | Taux d'apprentissage (learning rate) |


---
### Vecteur Gradient du MSE

Pour calculer
**Vecteur Gradient du MSE**
$$
\nabla_\theta MSE = \frac{2}{m} X^T (X\theta - y)
$$




| Symbole                    | Signification |
|----------------------------|--------------|
| $\nabla_\theta MSE$      | Gradient du MSE (vecteur des dÃ©rivÃ©es partielles) |
| $X$                      | Matrice des caractÃ©ristiques de taille $ m \times n $ |
| $y$                      | Vecteur des valeurs rÃ©elles de taille $ m \times 1 $ |
| $\theta$                 | Vecteur des paramÃ¨tres du modÃ¨le de taille $ n \times 1 $ |
| $X\theta$                | PrÃ©dictions du modÃ¨le (produit matriciel) de taille $ m \times 1 $ |
| $X^T$                    | TransposÃ©e de la matrice $ X $, de taille $ n \times m $ |
| $X^T (X\theta - y)$      | Gradient du MSE avant multiplication par $ \frac{2}{m} $ |
| $\alpha$                 | Taux d'apprentissage (learning rate) |

---

### coefficient de Pearson

â€‹<!--$$r = \frac{\sum (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum (x_i - \bar{x})^2 \sum (y_i - \bar{y})^2}}$$-->

![Coefficient de Pearson](img/pearson.png)


- **r** : le coefficient de corrÃ©lation linÃ©aire de Pearson  
- **$x_i$** et **$y_i$** : les valeurs des deux variables Ã©tudiÃ©es  
- **$\bar{x}$** et **$\bar{y}$** : les moyennes des variables $x$ et $y$ 
- Le numÃ©rateur mesure la covariance entre $x$ et $y$ 
- Le dÃ©nominateur normalise cette covariance par le produit des Ã©carts-types des deux variables  
<br>
[Retour Ã  l'index](#index)
